
very interesting initiative, and very interesting discussion, not dissimilar to what I have learned about the discussion in Sociology (https://doi.org/10.1162/99608f92.151c41e3). As so often, much of the discussion (and misunderstanding) surrounds data access rules, what I call the fallacy of the "all or nothing".

I like to frame the data access issue as a probability of access, or a number of researchers having access. Every access has rules, even if those rules may be "free access to all". But lots of "publicly available" datasets come with rules of access that are liberal, but not free. PSID, World Value Survey, Demographic Household Surveys, German Socio-Economic Panel, all have gradations of access, ranging from "sign/click through this agreement before downloading"  to "write a paragraph about what you want to do, but don't share the data"  to "you have to put this on a secure computer and BTW obtain IRB approval for your access". In fact, authors sometimes forget to abide by these rules, and we (data editors) must sometimes remind them of it, or correct the errors after publication ("take-down requests", see <https://aeadataeditor.github.io/posts/2024-11-01-psid-requests>). In fact, I get about 12-15 take-down requests or notifications of inappropriate data publication (or use!) per year (most, luckily, affecting cases that were simply passed through prior to my tenure, but we still miss some).

To put it simply, some amount of redistribution restriction (or even use restriction) is appropriate, where ethically necessitated (though this is often only a footnote in the various definitions of open science and the like).

Thus, counter arguments to the objections of the opponents of your policy are, IMHO, two-fold: use appropriate data distribution mechanisms, and teach the right tools. Ethics concerns are alleviated by clearly stating that some redistribution may occur to appropriately validated people (one can require IRB approval for secondary use, while not allowing the original researchers to gatekeep the data inappropriately, and modern IRBs are clearly aware of such options), that access by inappropriate tools or people can be limited (see QDR and Databrary), avoiding ethically costly errors of incomplete anonymization. Equity concerns are real, but can be largely mitigated (as far as I observe it) through knowledge transfer about how to effectively practice open (qualitative) science.

I would also emphasize that the legitimate concern voiced by opponents of data sharing ("raising concerns about the misuse of qualitative information") is precisely alleviated by... transparency and shared access to data.

It is generally better if more people can view, access, and analyze your data. But this does not happen in a void, and must —and can —be moderated for ethical reasons. Millions of people scrutinizing your collected criminal history is clearly not desirable nor optimal, but n=1 is also not optimal. Finding the right number of people with access is a challenge, but is feasible.